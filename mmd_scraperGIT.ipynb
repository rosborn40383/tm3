{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce395b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import PoolManager\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)  # Disable logging from the requests module\n",
    "#Change to the preferred directory\n",
    "basedir = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "### URLS\n",
    "LOGIN_URL = 'https://www.tm3.com/homepage/login.jsf'\n",
    "TAXEXEMPT_URL = 'https://www.tm3.com/mmdrewrite/mmd/14902.faces'\n",
    "TAXABLE_URL = 'https://www.tm3.com/mmdrewrite/mmd/TaxableYieldCurveChanges.faces'\n",
    "\n",
    "### Credentials\n",
    "USERNAME = 'REDACTED'\n",
    "PASSWORD = 'REDACTED'\n",
    "\n",
    "\n",
    "# Define the scrape_data function here\n",
    "def scrape_data(tax_feature, url):\n",
    "    logger.info('Scraping %s at %s...' % (tax_feature, url))\n",
    "    r = s.get(url)\n",
    "    t = r.text\n",
    "    soup = BeautifulSoup(t)\n",
    "    if tax_feature == 'taxexempt':\n",
    "        tgt_table = soup.find('table', {'class': 'data data14902'})\n",
    "    else:  # 'taxable'\n",
    "        tgt_table = soup.find('table', {'class': 'dataDL'})\n",
    "    rows = tgt_table.findAll('tr')\n",
    "    if len(soup.findAll('th')) > 0:\n",
    "        rows = rows[2:]\n",
    "    # get date\n",
    "    dt = get_table_dt(soup, tax_feature)\n",
    "\n",
    "    dates = []\n",
    "    scales = []\n",
    "    aaa_ylds = []\n",
    "    aa_ylds = []\n",
    "    a_ylds = []\n",
    "    baa_ylds = []\n",
    "    if tax_feature == 'taxexempt':\n",
    "        for row in rows:\n",
    "            cells = row.findAll('td')\n",
    "            dates.append(dt)\n",
    "            scales.append(cells[0].get_text())\n",
    "            aaa_ylds.append(cells[2].get_text())\n",
    "            aa_ylds.append(cells[5].get_text())\n",
    "            a_ylds.append(cells[6].get_text())\n",
    "            baa_ylds.append(cells[7].get_text())\n",
    "    else:  # 'taxable'\n",
    "        for row in rows:\n",
    "            cells = row.findAll('td')\n",
    "            dates.append(dt)\n",
    "            scales.append(cells[1].get_text())\n",
    "            aaa_ylds.append(cells[3].get_text())\n",
    "            aa_ylds.append(cells[5].get_text())\n",
    "            a_ylds.append(cells[7].get_text())\n",
    "            baa_ylds.append(cells[9].get_text())\n",
    "    d = {'date': dates, 'scale': scales, 'AAA': aaa_ylds, 'AA': aa_ylds, 'A': a_ylds, 'BAA': baa_ylds}\n",
    "    df = pd.DataFrame(d)\n",
    "    # reshape df for database insert\n",
    "    df.mlt = pd.melt(df, id_vars=['date', 'scale'], var_name='rating')\n",
    "    return df.mlt, tax_feature\n",
    "\n",
    "# Define the get_table_dt function here\n",
    "def get_table_dt(io, tax_feature):\n",
    "    dt_str = io.find('h2', {'class': 'pgSubHeader'}).get_text()\n",
    "    match = re.search(r'(\\d+/\\d+/\\d+)', dt_str)\n",
    "    dt_str = match.group(1)\n",
    "    try:\n",
    "        return datetime.strptime(dt_str, '%m/%d/%Y').strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        logger.warning(e)\n",
    "\n",
    "def insert_dframe(tablename, dframe, dbpath):\n",
    "    db = sqlite3.connect(dbpath)\n",
    "    curs = db.cursor()\n",
    "    # Create the table if needed\n",
    "    tblstr = 'CREATE TABLE IF NOT EXISTS %s (date TEXT, scale INTEGER, rating TEXT, value REAL, PRIMARY KEY (date, scale, rating))' % tablename\n",
    "    if curs.execute(tblstr):\n",
    "        logger.info('Table %s created or already exists...' % tablename)\n",
    "    else:\n",
    "        logger.error('Error creating table %s...' % tablename)\n",
    "    # Insert data row by row, avoiding duplicates\n",
    "    for _, row in dframe.iterrows():\n",
    "        try:\n",
    "            curs.execute('INSERT OR IGNORE INTO %s VALUES (?, ?, ?, ?)' % tablename, tuple(row))\n",
    "        except sqlite3.IntegrityError as e:\n",
    "            logger.info(e)\n",
    "    db.commit()\n",
    "    logger.info('Inserted %s rows into %s...' % (len(dframe), tablename))\n",
    "    curs.close()\n",
    "    db.close()\n",
    "\n",
    "\n",
    "### Main Program\n",
    "if __name__ == '__main__':\n",
    "    ### Stuff required for a persistent session\n",
    "    class MyAdapter(HTTPAdapter):\n",
    "        def init_poolmanager(self, connections, maxsize, block):\n",
    "            self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize, block=block, ssl_version=ssl.PROTOCOL_TLSv1)\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        logging.info('Opening session...')\n",
    "        s.mount('https://', MyAdapter())\n",
    "        # Build payload that will eventually be posted to login\n",
    "        payload = {}\n",
    "        # Find hidden inputs\n",
    "        \"\"\" uncomment line below if you run into any certificate verification issues \"\"\"\n",
    "        result = s.get(LOGIN_URL, verify=False)\n",
    "        #result = s.get(LOGIN_URL)\n",
    "        c = result.content\n",
    "        soup = BeautifulSoup(c)\n",
    "        hidden_inputs = soup.find_all('input', type='hidden')\n",
    "        for hidden_input in hidden_inputs:\n",
    "            name = hidden_input.get('name')\n",
    "            payload[name] = hidden_input.get('value')\n",
    "        payload['username'] = USERNAME\n",
    "        payload['password'] = PASSWORD\n",
    "        payload['loginButton'] = 'Login'\n",
    "        logger.debug('Payload is %s' % payload)\n",
    "        # Attempt to login\n",
    "        logger.info('Attempting to login...')\n",
    "        s.post(LOGIN_URL, data=payload, timeout=30.0)\n",
    "        dbpath = os.path.join(basedir, os.pardir, 'ksm.db') #Change db to desired databse location\n",
    "        df, tbl = scrape_data('taxexempt', TAXEXEMPT_URL)\n",
    "        insert_dframe(tbl, df, dbpath)\n",
    "        df, tbl = scrape_data('taxable', TAXABLE_URL)\n",
    "        insert_dframe(tbl, df, dbpath)\n",
    "        logger.info('Done...')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
